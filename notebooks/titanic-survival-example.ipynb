{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction - Example Notebook\n",
    "\n",
    "This notebook demonstrates the complete ML workflow for the mlsys project:\n",
    "1. Load and explore data\n",
    "2. Perform feature engineering\n",
    "3. Train and evaluate a classification model\n",
    "4. Upload trained model to GCS\n",
    "\n",
    "**Model**: Titanic survival prediction (binary classification)\n",
    "\n",
    "**Data Source**: sklearn's OpenML Titanic dataset (for demonstration purposes)\n",
    "\n",
    "**Model Version**: v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and configure environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import json\n",
    "import warnings\n",
    "from datetime import UTC, datetime\n",
    "\n",
    "# Third-party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# mlsys utilities\n",
    "from mlsys.gcs import gcs_put\n",
    "from mlsys.settings import GCS_BUCKET_MODELS_DEV\n",
    "from mlsys.vis import setup_plot_style\n",
    "\n",
    "# Configure\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "setup_plot_style()\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "For this example, we'll use sklearn's Titanic dataset. In production, you would use `bq_get()` to fetch data from BigQuery:\n",
    "\n",
    "```python\n",
    "from mlsys.bq import bq_get\n",
    "\n",
    "df = bq_get(\"\"\"\n",
    "    SELECT * \n",
    "    FROM `my-project.my_dataset.titanic_training`\n",
    "    WHERE date >= '2024-01-01'\n",
    "\"\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset from sklearn\n",
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True, parser=\"auto\")\n",
    "df = titanic.frame\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\"Count\": missing, \"Percentage\": missing_pct})\n",
    "missing_df[missing_df[\"Count\"] > 0].sort_values(\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival distribution\n",
    "survival_counts = df[\"survived\"].value_counts()\n",
    "print(\"Survival Counts:\")\n",
    "print(survival_counts)\n",
    "print(f\"\\nSurvival Rate: {(survival_counts[1] / len(df)) * 100:.2f}%\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "survival_counts.plot(kind=\"bar\", ax=ax[0])\n",
    "ax[0].set_title(\"Survival Counts\")\n",
    "ax[0].set_xlabel(\"Survived\")\n",
    "ax[0].set_ylabel(\"Count\")\n",
    "ax[0].set_xticklabels([\"No\", \"Yes\"], rotation=0)\n",
    "\n",
    "survival_counts.plot(kind=\"pie\", autopct=\"%1.1f%%\", ax=ax[1], labels=[\"Died\", \"Survived\"])\n",
    "ax[1].set_title(\"Survival Rate\")\n",
    "ax[1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival by passenger class\n",
    "survival_by_class = df.groupby(\"pclass\")[\"survived\"].apply(lambda x: (x == \"1\").mean())\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# By class\n",
    "survival_by_class.plot(kind=\"bar\", ax=ax[0])\n",
    "ax[0].set_title(\"Survival Rate by Passenger Class\")\n",
    "ax[0].set_xlabel(\"Class\")\n",
    "ax[0].set_ylabel(\"Survival Rate\")\n",
    "ax[0].set_xticklabels([\"1st\", \"2nd\", \"3rd\"], rotation=0)\n",
    "\n",
    "# By sex\n",
    "survival_by_sex = df.groupby(\"sex\")[\"survived\"].apply(lambda x: (x == \"1\").mean())\n",
    "survival_by_sex.plot(kind=\"bar\", ax=ax[1])\n",
    "ax[1].set_title(\"Survival Rate by Sex\")\n",
    "ax[1].set_xlabel(\"Sex\")\n",
    "ax[1].set_ylabel(\"Survival Rate\")\n",
    "ax[1].set_xticklabels([\"Female\", \"Male\"], rotation=0)\n",
    "\n",
    "# Age distribution by survival\n",
    "df[df[\"survived\"] == \"1\"][\"age\"].hist(bins=30, alpha=0.5, label=\"Survived\", ax=ax[2])\n",
    "df[df[\"survived\"] == \"0\"][\"age\"].hist(bins=30, alpha=0.5, label=\"Died\", ax=ax[2])\n",
    "ax[2].set_title(\"Age Distribution by Survival\")\n",
    "ax[2].set_xlabel(\"Age\")\n",
    "ax[2].set_ylabel(\"Count\")\n",
    "ax[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Prepare features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_model = df.copy()\n",
    "\n",
    "# Convert target to numeric\n",
    "df_model[\"survived\"] = df_model[\"survived\"].astype(int)\n",
    "\n",
    "# Select features for modeling\n",
    "# Using features that are most predictive and have reasonable completeness\n",
    "feature_cols = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\"]\n",
    "\n",
    "# Create feature matrix and target\n",
    "X = df_model[feature_cols].copy()\n",
    "y = df_model[\"survived\"]\n",
    "\n",
    "print(f\"Feature shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"Missing values before imputation:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Impute age with median\n",
    "X[\"age\"] = X[\"age\"].fillna(X[\"age\"].median())\n",
    "\n",
    "# Impute fare with median\n",
    "X[\"fare\"] = X[\"fare\"].fillna(X[\"fare\"].median())\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "X[\"sex\"] = X[\"sex\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "print(\"Feature matrix after encoding:\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any remaining rows with missing values\n",
    "mask = X.isnull().any(axis=1) | y.isnull()\n",
    "X = X[~mask]\n",
    "y = y[~mask]\n",
    "\n",
    "print(f\"Final dataset shape: {X.shape}\")\n",
    "print(f\"Removed {mask.sum()} rows with missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(\"\\nTarget distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling\n",
    "\n",
    "Scale numerical features to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames for convenience\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"Features scaled successfully!\")\n",
    "print(\"\\nScaled training data (first 5 rows):\")\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Train a Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=10, min_samples_split=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\"feature\": X_train.columns, \"importance\": model.feature_importances_}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance[\"feature\"], feature_importance[\"importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Evaluate model performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Confusion matrix\n",
    "im = ax[0].imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "ax[0].figure.colorbar(im, ax=ax[0])\n",
    "ax[0].set(\n",
    "    xticks=np.arange(cm.shape[1]),\n",
    "    yticks=np.arange(cm.shape[0]),\n",
    "    xticklabels=[\"Died\", \"Survived\"],\n",
    "    yticklabels=[\"Died\", \"Survived\"],\n",
    "    title=\"Confusion Matrix\",\n",
    "    ylabel=\"True label\",\n",
    "    xlabel=\"Predicted label\",\n",
    ")\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax[0].text(j, i, format(cm[i, j], \"d\"), ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "ax[1].plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.4f})\")\n",
    "ax[1].plot([0, 1], [0, 1], \"k--\", label=\"Random classifier\")\n",
    "ax[1].set_xlabel(\"False Positive Rate\")\n",
    "ax[1].set_ylabel(\"True Positive Rate\")\n",
    "ax[1].set_title(\"ROC Curve\")\n",
    "ax[1].legend()\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation\n",
    "\n",
    "Verify model performance with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation on full dataset\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Cross-validation ROC AUC scores: {cv_scores}\")\n",
    "print(f\"Mean ROC AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Upload Model to GCS\n",
    "\n",
    "Save the trained model and scaler to Google Cloud Storage for deployment.\n",
    "\n",
    "**Model artifacts**:\n",
    "- `model.pkl`: Trained RandomForest classifier\n",
    "- `scaler.pkl`: StandardScaler fitted on training data\n",
    "\n",
    "**GCS path**: `gs://ml-models-dev/titanic-survival/v1/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model metadata\n",
    "MODEL_NAME = \"titanic-survival\"\n",
    "MODEL_VERSION = \"v1\"\n",
    "BUCKET_NAME = GCS_BUCKET_MODELS_DEV\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Version: {MODEL_VERSION}\")\n",
    "print(f\"Bucket: {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model artifact\n",
    "model_path = f\"{MODEL_NAME}/{MODEL_VERSION}/model.pkl\"\n",
    "print(f\"Uploading model to gs://{BUCKET_NAME}/{model_path}\")\n",
    "\n",
    "gcs_put(obj=model, bucket_name=BUCKET_NAME, blob_path=model_path)\n",
    "print(\"Model uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload scaler\n",
    "scaler_path = f\"{MODEL_NAME}/{MODEL_VERSION}/scaler.pkl\"\n",
    "print(f\"Uploading scaler to gs://{BUCKET_NAME}/{scaler_path}\")\n",
    "\n",
    "gcs_put(obj=scaler, bucket_name=BUCKET_NAME, blob_path=scaler_path)\n",
    "print(\"Scaler uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Metadata\n",
    "\n",
    "Document model metadata for tracking and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model metadata\n",
    "metadata = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"model_version\": MODEL_VERSION,\n",
    "    \"model_type\": \"RandomForestClassifier\",\n",
    "    \"training_date\": datetime.now(UTC).isoformat(),\n",
    "    \"features\": list(X.columns),\n",
    "    \"target\": \"survived\",\n",
    "    \"training_samples\": len(X_train),\n",
    "    \"test_samples\": len(X_test),\n",
    "    \"test_accuracy\": float(accuracy),\n",
    "    \"test_roc_auc\": float(roc_auc),\n",
    "    \"cv_roc_auc_mean\": float(cv_scores.mean()),\n",
    "    \"cv_roc_auc_std\": float(cv_scores.std()),\n",
    "    \"hyperparameters\": {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 10,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    \"gcs_path\": f\"gs://{BUCKET_NAME}/{MODEL_NAME}/{MODEL_VERSION}/\",\n",
    "}\n",
    "\n",
    "print(\"Model Metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata to GCS\n",
    "metadata_path = f\"{MODEL_NAME}/{MODEL_VERSION}/metadata.json\"\n",
    "print(f\"Uploading metadata to gs://{BUCKET_NAME}/{metadata_path}\")\n",
    "\n",
    "gcs_put(obj=json.dumps(metadata, indent=2), bucket_name=BUCKET_NAME, blob_path=metadata_path)\n",
    "print(\"Metadata uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Model Performance\n",
    "- **Test Accuracy**: {accuracy:.4f}\n",
    "- **Test ROC AUC**: {roc_auc:.4f}\n",
    "- **CV ROC AUC**: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\n",
    "\n",
    "### Artifacts Uploaded to GCS\n",
    "1. **Model**: `gs://ml-models-dev/titanic-survival/v1/model.pkl`\n",
    "2. **Scaler**: `gs://ml-models-dev/titanic-survival/v1/scaler.pkl`\n",
    "3. **Metadata**: `gs://ml-models-dev/titanic-survival/v1/metadata.json`\n",
    "\n",
    "### Next Steps\n",
    "1. Create an Airflow DAG to schedule predictions\n",
    "2. Deploy to Cloud Run for production\n",
    "3. Monitor model performance over time\n",
    "4. Iterate on features and hyperparameters for improved performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
